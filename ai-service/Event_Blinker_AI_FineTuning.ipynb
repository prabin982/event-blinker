{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Event Blinker AI Fine-Tuning Notebook\n",
                "\n",
                "This notebook will help you fine-tune a language model for your Event Blinker application.\n",
                "\n",
                "## What this notebook does:\n",
                "1. **Checks GPU availability** (T4/V100/A100)\n",
                "2. **Installs required libraries** (Unsloth, PEFT, transformers)\n",
                "3. **Loads a base model** (Llama 3 8B or Mistral 7B)\n",
                "4. **Fine-tunes on event assistant data**\n",
                "5. **Exports to Ollama format (GGUF)**\n",
                "6. **Downloads the model for local use**\n",
                "\n",
                "---\n",
                "**IMPORTANT:** Go to Runtime > Change runtime type > Select **T4 GPU** (free) or **A100** (Colab Pro)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Check GPU and Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "import torch\n",
                "print(f\"\\nüîç Checking GPU...\")\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "    print(\"\\n‚úÖ GPU is ready for fine-tuning!\")\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è No GPU detected! Go to Runtime > Change runtime type > Select T4 GPU\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Unsloth (fastest fine-tuning library - 2x faster than HuggingFace)\n",
                "%%capture\n",
                "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
                "!pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
                "!pip install datasets huggingface_hub\n",
                "\n",
                "print(\"\\n‚úÖ All dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load Base Model (Llama 3 8B with 4-bit Quantization)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from unsloth import FastLanguageModel\n",
                "import torch\n",
                "\n",
                "# Configuration\n",
                "max_seq_length = 2048  # Can go up to 8192 for longer contexts\n",
                "dtype = None  # Auto-detect (float16 for T4, bfloat16 for A100)\n",
                "load_in_4bit = True  # Use 4-bit quantization to save memory\n",
                "\n",
                "# Load the base model\n",
                "# Options:\n",
                "# - \"unsloth/llama-3-8b-bnb-4bit\" (Llama 3 8B - RECOMMENDED)\n",
                "# - \"unsloth/mistral-7b-v0.3-bnb-4bit\" (Mistral 7B)\n",
                "# - \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\" (Llama 3.1 8B)\n",
                "# - \"unsloth/gemma-2b-bnb-4bit\" (Smaller, faster)\n",
                "\n",
                "model, tokenizer = FastLanguageModel.from_pretrained(\n",
                "    model_name=\"unsloth/llama-3-8b-bnb-4bit\",\n",
                "    max_seq_length=max_seq_length,\n",
                "    dtype=dtype,\n",
                "    load_in_4bit=load_in_4bit,\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Model loaded successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add LoRA adapters for efficient fine-tuning\n",
                "# This only trains ~1-10% of parameters, saving memory and time\n",
                "\n",
                "model = FastLanguageModel.get_peft_model(\n",
                "    model,\n",
                "    r=16,  # LoRA rank (higher = more capacity, but slower)\n",
                "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
                "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
                "    lora_alpha=16,\n",
                "    lora_dropout=0,  # 0 is optimized\n",
                "    bias=\"none\",\n",
                "    use_gradient_checkpointing=\"unsloth\",  # 30% less memory\n",
                "    random_state=3407,\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ LoRA adapters added!\")\n",
                "print(f\"Trainable parameters: {model.print_trainable_parameters()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Prepare Training Data for Event Blinker\n",
                "\n",
                "### Fine-tuning Data Categories:\n",
                "1. **Event Information** - Questions about event details, time, location, price\n",
                "2. **Navigation/Directions** - How to get to events, parking info\n",
                "3. **Booking/Registration** - How to register, ticket purchase\n",
                "4. **General Assistance** - Ride-sharing, food options, accessibility\n",
                "5. **Organizer Help** - Creating events, managing attendees"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Event Blinker Training Dataset\n",
                "# This is your custom training data for the event assistant\n",
                "\n",
                "event_blinker_data = [\n",
                "    # === EVENT INFORMATION ===\n",
                "    {\n",
                "        \"instruction\": \"What time does the event start?\",\n",
                "        \"context\": \"Event: Summer Music Festival. Location: Central Park. Starts at: 2024-07-15 18:00. Price: $50.\",\n",
                "        \"response\": \"The Summer Music Festival starts at 6:00 PM on July 15th, 2024. Make sure to arrive a bit early to find good spots!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Where is this event located?\",\n",
                "        \"context\": \"Event: Tech Meetup. Location: Innovation Hub, 123 Tech Street. Starts at: 2024-08-20 10:00.\",\n",
                "        \"response\": \"The Tech Meetup is at Innovation Hub, located at 123 Tech Street. It's in the downtown tech district.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"How much are the tickets?\",\n",
                "        \"context\": \"Event: Comedy Night. Location: Laugh Factory. Price: $25. Capacity: 200.\",\n",
                "        \"response\": \"Tickets for Comedy Night are $25 each. The venue has a capacity of 200, so I'd recommend booking early!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Is this event free?\",\n",
                "        \"context\": \"Event: Community Cleanup Day. Location: Riverside Park. Price: free.\",\n",
                "        \"response\": \"Yes! Community Cleanup Day is completely free to attend. Just show up at Riverside Park and join the volunteers!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"What is this event about?\",\n",
                "        \"context\": \"Event: AI Workshop. Description: Learn the basics of machine learning, neural networks, and build your first AI model.\",\n",
                "        \"response\": \"The AI Workshop is designed to teach you machine learning basics, how neural networks work, and guide you through building your first AI model. Perfect for beginners!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"How many people can attend?\",\n",
                "        \"context\": \"Event: Startup Pitch Night. Capacity: 150. Current attendance: 89.\",\n",
                "        \"response\": \"Startup Pitch Night has a capacity of 150 attendees. Currently, 89 spots are taken, so 61 spots are still available. Register soon!\"\n",
                "    },\n",
                "\n",
                "    # === NAVIGATION & DIRECTIONS ===\n",
                "    {\n",
                "        \"instruction\": \"How do I get to the event?\",\n",
                "        \"context\": \"Event: Art Exhibition. Location: Modern Art Gallery, 456 Art Avenue.\",\n",
                "        \"response\": \"The Art Exhibition is at Modern Art Gallery, 456 Art Avenue. You can use the Event Blinker app's map feature to get turn-by-turn directions. The gallery is accessible by both public transit and car.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Is there parking available?\",\n",
                "        \"context\": \"Event: Food Festival. Location: City Convention Center.\",\n",
                "        \"response\": \"The City Convention Center has a large parking garage attached. Parking typically costs $10-15 for the day. There's also street parking nearby, but it fills up fast during events.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Can I take public transport?\",\n",
                "        \"context\": \"Event: Marathon Race. Location: Downtown Sports Complex.\",\n",
                "        \"response\": \"Yes! The Downtown Sports Complex is well-served by public transit. Take the Blue Line to Central Station, then it's a 5-minute walk. Bus routes 12 and 34 also stop nearby.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"What's the best route from the airport?\",\n",
                "        \"context\": \"Event: International Conference. Location: Grand Hotel Conference Center.\",\n",
                "        \"response\": \"From the airport, take the Airport Express train to Central Station (30 mins), then a taxi or rideshare to Grand Hotel (10 mins). Total journey is about 45 minutes. Alternatively, taxis from the airport cost around $40-50.\"\n",
                "    },\n",
                "\n",
                "    # === BOOKING & REGISTRATION ===\n",
                "    {\n",
                "        \"instruction\": \"How do I register for this event?\",\n",
                "        \"context\": \"Event: Yoga Retreat. Registration: Open.\",\n",
                "        \"response\": \"To register for the Yoga Retreat, tap the 'Register' or 'Book Now' button on the event page in the app. You'll be guided through the registration process. Make sure you're logged in first!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Can I get a refund?\",\n",
                "        \"context\": \"Event: Photography Workshop. Price: $75.\",\n",
                "        \"response\": \"Refund policies vary by event organizer. For the Photography Workshop, I'd recommend contacting the organizer directly through the chat feature. Generally, refunds are available up to 48 hours before the event.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Can I bring a friend?\",\n",
                "        \"context\": \"Event: Movie Night. Capacity: 100. Current: 45.\",\n",
                "        \"response\": \"Absolutely! Movie Night has plenty of space - 55 spots are still available. Your friend will need to register separately through the app, or you can purchase multiple tickets if that option is available.\"\n",
                "    },\n",
                "\n",
                "    # === RIDE SHARING ===\n",
                "    {\n",
                "        \"instruction\": \"Are there any ride shares to this event?\",\n",
                "        \"context\": \"Event: Mountain Hiking Trip. Location: Trailhead Parking Lot.\",\n",
                "        \"response\": \"Check the 'Rides' tab on the event page to see if other attendees are offering ride shares. You can also offer your own ride if you're driving! It's a great way to meet fellow hikers and split costs.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"How does ride sharing work?\",\n",
                "        \"context\": \"General question about Event Blinker features.\",\n",
                "        \"response\": \"Event Blinker's ride sharing lets you connect with other attendees! Drivers can offer seats, and riders can request rides. Simply go to any event, tap 'Rides', and either offer a ride or browse available ones. You can chat with drivers before confirming.\"\n",
                "    },\n",
                "\n",
                "    # === GENERAL ASSISTANCE ===\n",
                "    {\n",
                "        \"instruction\": \"What should I bring?\",\n",
                "        \"context\": \"Event: Beach Party. Location: Sunset Beach.\",\n",
                "        \"response\": \"For the Beach Party at Sunset Beach, bring: sunscreen, towel, swimwear, water bottle, and maybe a change of clothes. The organizer may provide some refreshments, but check the event description for details!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Is the venue wheelchair accessible?\",\n",
                "        \"context\": \"Event: Classical Concert. Location: Symphony Hall.\",\n",
                "        \"response\": \"Symphony Hall is fully wheelchair accessible with ramps, elevators, and accessible seating areas. Contact the venue or organizer in advance to reserve accessible seating.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Will there be food?\",\n",
                "        \"context\": \"Event: All-Day Conference. Duration: 8 hours.\",\n",
                "        \"response\": \"For an all-day conference, catering is usually provided (coffee breaks, lunch). Check the event description for specific details. If not mentioned, there are usually cafeterias or restaurants nearby.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"What's the dress code?\",\n",
                "        \"context\": \"Event: Gala Dinner. Location: Luxury Hotel Ballroom.\",\n",
                "        \"response\": \"For a Gala Dinner at a Luxury Hotel Ballroom, the dress code is typically formal/black tie. Men should wear suits or tuxedos, women should wear evening dresses or formal attire.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Can I bring my kids?\",\n",
                "        \"context\": \"Event: Family Fun Day. Target audience: Families.\",\n",
                "        \"response\": \"Absolutely! Family Fun Day is designed for families and kids are very welcome! There will likely be activities for all ages. Check the event description for specific kids' activities.\"\n",
                "    },\n",
                "\n",
                "    # === ORGANIZER HELP ===\n",
                "    {\n",
                "        \"instruction\": \"How do I create an event?\",\n",
                "        \"context\": \"User is an organizer.\",\n",
                "        \"response\": \"To create an event: 1) Log into the web portal at your-event-blinker-url.com, 2) Click 'Create Event', 3) Fill in title, description, date/time, location, and price, 4) Add images, 5) Click 'Publish'. Your event will appear on the map immediately!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"How do I see who's attending my event?\",\n",
                "        \"context\": \"User is an organizer checking their event.\",\n",
                "        \"response\": \"Go to your organizer dashboard and select the event. You'll see the 'Attendees' tab with a full list of registered attendees, their check-in status, and contact info (if provided).\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"How do I update my event details?\",\n",
                "        \"context\": \"User wants to edit their event.\",\n",
                "        \"response\": \"To update your event: 1) Go to your organizer dashboard, 2) Find your event and click 'Edit', 3) Make your changes, 4) Click 'Save'. Attendees will be notified of major changes automatically.\"\n",
                "    },\n",
                "\n",
                "    # === EDGE CASES & UNKNOWN ===\n",
                "    {\n",
                "        \"instruction\": \"What's the weather going to be like?\",\n",
                "        \"context\": \"Event: Outdoor Concert.\",\n",
                "        \"response\": \"I don't have access to weather forecasts, but I recommend checking your weather app closer to the event date. For outdoor events, it's always good to bring layers and check if the organizer has a rain policy!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Can you call the organizer for me?\",\n",
                "        \"context\": \"User request for phone call.\",\n",
                "        \"response\": \"I can't make phone calls, but you can contact the organizer directly through the event's chat feature in the app. Tap on the event, then 'Contact Organizer' or 'Chat' to send them a message.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"What if the event is cancelled?\",\n",
                "        \"context\": \"General question.\",\n",
                "        \"response\": \"If an event is cancelled, you should receive a notification from Event Blinker. Refund policies depend on the organizer - check your booking confirmation or contact them directly. Most organizers offer full refunds for cancellations.\"\n",
                "    },\n",
                "\n",
                "    # === CONVERSATIONAL & GREETINGS ===\n",
                "    {\n",
                "        \"instruction\": \"Hello!\",\n",
                "        \"context\": \"General greeting.\",\n",
                "        \"response\": \"Hello! üëã I'm your Event Blinker assistant. I can help you with event information, directions, registration, and more. What would you like to know?\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Thank you!\",\n",
                "        \"context\": \"User expressing gratitude.\",\n",
                "        \"response\": \"You're welcome! Enjoy your event! üéâ If you have any more questions, just ask. Have a great time!\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"What can you help me with?\",\n",
                "        \"context\": \"User asking about capabilities.\",\n",
                "        \"response\": \"I can help you with: \\n‚Ä¢ Event details (time, location, price)\\n‚Ä¢ Directions and parking info\\n‚Ä¢ Registration and booking\\n‚Ä¢ Finding ride shares\\n‚Ä¢ General event questions\\n\\nJust ask about any event you're interested in!\"\n",
                "    }\n",
                "]\n",
                "\n",
                "print(f\"\\n‚úÖ Created {len(event_blinker_data)} training examples!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Format data for training (Alpaca-style prompt format)\n",
                "from datasets import Dataset\n",
                "\n",
                "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with context that provides further information. Write a response that appropriately completes the request.\n",
                "\n",
                "### Instruction:\n",
                "{instruction}\n",
                "\n",
                "### Context:\n",
                "{context}\n",
                "\n",
                "### Response:\n",
                "{response}\"\"\"\n",
                "\n",
                "EOS_TOKEN = tokenizer.eos_token\n",
                "\n",
                "def format_prompt(example):\n",
                "    return {\n",
                "        \"text\": alpaca_prompt.format(\n",
                "            instruction=example[\"instruction\"],\n",
                "            context=example[\"context\"],\n",
                "            response=example[\"response\"]\n",
                "        ) + EOS_TOKEN\n",
                "    }\n",
                "\n",
                "# Create dataset\n",
                "dataset = Dataset.from_list(event_blinker_data)\n",
                "dataset = dataset.map(format_prompt)\n",
                "\n",
                "print(\"\\n‚úÖ Dataset formatted!\")\n",
                "print(f\"\\nüìù Sample training example:\\n\")\n",
                "print(dataset[0][\"text\"][:500] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Fine-Tune the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from trl import SFTTrainer\n",
                "from transformers import TrainingArguments\n",
                "from unsloth import is_bfloat16_supported\n",
                "\n",
                "trainer = SFTTrainer(\n",
                "    model=model,\n",
                "    tokenizer=tokenizer,\n",
                "    train_dataset=dataset,\n",
                "    dataset_text_field=\"text\",\n",
                "    max_seq_length=max_seq_length,\n",
                "    dataset_num_proc=2,\n",
                "    packing=False,  # Can be True for faster training on short examples\n",
                "    args=TrainingArguments(\n",
                "        per_device_train_batch_size=2,\n",
                "        gradient_accumulation_steps=4,\n",
                "        warmup_steps=5,\n",
                "        max_steps=60,  # Increase for more epochs (e.g., 200 for production)\n",
                "        learning_rate=2e-4,\n",
                "        fp16=not is_bfloat16_supported(),\n",
                "        bf16=is_bfloat16_supported(),\n",
                "        logging_steps=10,\n",
                "        optim=\"adamw_8bit\",\n",
                "        weight_decay=0.01,\n",
                "        lr_scheduler_type=\"linear\",\n",
                "        seed=3407,\n",
                "        output_dir=\"outputs\",\n",
                "    ),\n",
                ")\n",
                "\n",
                "print(\"\\nüöÄ Starting training...\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model!\n",
                "trainer_stats = trainer.train()\n",
                "\n",
                "print(\"\\n‚úÖ Training complete!\")\n",
                "print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n",
                "print(f\"Training loss: {trainer_stats.metrics['train_loss']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Test the Fine-Tuned Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the fine-tuned model\n",
                "FastLanguageModel.for_inference(model)\n",
                "\n",
                "test_prompts = [\n",
                "    {\"instruction\": \"What time does the event start?\", \"context\": \"Event: Jazz Night. Starts at: 8:00 PM. Location: Blue Note Cafe.\"},\n",
                "    {\"instruction\": \"Is there parking available?\", \"context\": \"Event: Food Truck Festival. Location: Downtown Plaza.\"},\n",
                "    {\"instruction\": \"How do I register?\", \"context\": \"Event: Coding Bootcamp. Price: $200.\"},\n",
                "]\n",
                "\n",
                "for test in test_prompts:\n",
                "    prompt = alpaca_prompt.format(\n",
                "        instruction=test[\"instruction\"],\n",
                "        context=test[\"context\"],\n",
                "        response=\"\"\n",
                "    )\n",
                "    \n",
                "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
                "    outputs = model.generate(**inputs, max_new_tokens=150, temperature=0.7)\n",
                "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    \n",
                "    # Extract just the response part\n",
                "    if \"### Response:\" in response:\n",
                "        response = response.split(\"### Response:\")[-1].strip()\n",
                "    \n",
                "    print(f\"\\n‚ùì {test['instruction']}\")\n",
                "    print(f\"üìç Context: {test['context']}\")\n",
                "    print(f\"ü§ñ Response: {response}\")\n",
                "    print(\"-\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Export Model for Ollama (GGUF Format)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the LoRA adapters first\n",
                "model.save_pretrained(\"event_blinker_lora\")\n",
                "tokenizer.save_pretrained(\"event_blinker_lora\")\n",
                "print(\"\\n‚úÖ LoRA adapters saved!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to GGUF format for Ollama\n",
                "# Quantization options:\n",
                "# - q4_k_m: Best balance of size and quality (RECOMMENDED)\n",
                "# - q5_k_m: Slightly larger, slightly better quality\n",
                "# - q8_0: Largest, best quality\n",
                "\n",
                "model.save_pretrained_gguf(\n",
                "    \"event_blinker_model\",\n",
                "    tokenizer,\n",
                "    quantization_method=\"q4_k_m\"\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Model exported to GGUF format!\")\n",
                "print(\"\\nFile: event_blinker_model-unsloth.Q4_K_M.gguf\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Modelfile for Ollama\n",
                "modelfile_content = '''FROM ./event_blinker_model-unsloth.Q4_K_M.gguf\n",
                "\n",
                "TEMPLATE \"\"\"Below is an instruction that describes a task, paired with context that provides further information. Write a response that appropriately completes the request.\n",
                "\n",
                "### Instruction:\n",
                "{{ .Prompt }}\n",
                "\n",
                "### Context:\n",
                "{{ .Context }}\n",
                "\n",
                "### Response:\n",
                "\"\"\"\n",
                "\n",
                "SYSTEM \"You are an event assistant for Event Blinker app. Be concise, friendly, and helpful. Help users with event information, directions, registration, and general questions.\"\n",
                "\n",
                "PARAMETER temperature 0.7\n",
                "PARAMETER top_p 0.9\n",
                "PARAMETER stop \"### Instruction:\"\n",
                "PARAMETER stop \"### Context:\"\n",
                "'''\n",
                "\n",
                "with open(\"Modelfile\", \"w\") as f:\n",
                "    f.write(modelfile_content)\n",
                "\n",
                "print(\"\\n‚úÖ Modelfile created!\")\n",
                "print(\"\\nüìù Modelfile contents:\")\n",
                "print(modelfile_content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Zip the model files for download\n",
                "!zip -r event_blinker_ollama_model.zip event_blinker_model-unsloth.Q4_K_M.gguf Modelfile\n",
                "\n",
                "print(\"\\n‚úÖ Model files zipped!\")\n",
                "print(\"\\nüì¶ Download: event_blinker_ollama_model.zip\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download the model\n",
                "from google.colab import files\n",
                "files.download(\"event_blinker_ollama_model.zip\")\n",
                "\n",
                "print(\"\\nüéâ Download started! After downloading:\")\n",
                "print(\"\")\n",
                "print(\"1. Unzip the file\")\n",
                "print(\"2. Move files to your Event Blinker project\")\n",
                "print(\"3. Run: ollama create event-blinker -f Modelfile\")\n",
                "print(\"4. Update your .env: OLLAMA_MODEL=event-blinker\")\n",
                "print(\"5. Restart your AI service!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéâ Complete!\n",
                "\n",
                "### How to Use the Fine-Tuned Model:\n",
                "\n",
                "1. **Download** the `event_blinker_ollama_model.zip` file\n",
                "2. **Unzip** and copy files to your project\n",
                "3. **Create the Ollama model**:\n",
                "   ```bash\n",
                "   ollama create event-blinker -f Modelfile\n",
                "   ```\n",
                "4. **Update your AI service .env**:\n",
                "   ```\n",
                "   OLLAMA_MODEL=event-blinker\n",
                "   ```\n",
                "5. **Restart the AI service** and test!\n",
                "\n",
                "---\n",
                "\n",
                "### Tips for Better Fine-Tuning:\n",
                "\n",
                "1. **More data = Better results**: Add more training examples (100-500 recommended)\n",
                "2. **More epochs**: Increase `max_steps` to 100-200 for better learning\n",
                "3. **Domain-specific data**: Add real event Q&As from your users\n",
                "4. **Categories to add**:\n",
                "   - Safety/emergency info\n",
                "   - Weather-related questions\n",
                "   - Group bookings\n",
                "   - Vendor/sponsor questions\n",
                "   - Multi-day event handling"
            ]
        }
    ]
}